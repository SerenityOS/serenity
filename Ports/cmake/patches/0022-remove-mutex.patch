diff --git a/Source/cmQtAutoGenerator.cxx b/Source/cmQtAutoGenerator.cxx
index ee2bc09..a1c5821 100644
--- a/Source/cmQtAutoGenerator.cxx
+++ b/Source/cmQtAutoGenerator.cxx
@@ -61,7 +61,9 @@ void cmQtAutoGenerator::Logger::Info(GenT genType,
   std::string msg = cmStrCat(GeneratorName(genType), ": ", message,
                              cmHasSuffix(message, '\n') ? "" : "\n");
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Mutex_);
+#endif
     cmSystemTools::Stdout(msg);
   }
 }
@@ -80,7 +82,9 @@ void cmQtAutoGenerator::Logger::Warning(GenT genType,
                    message, cmHasSuffix(message, '\n') ? "\n" : "\n\n");
   }
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Mutex_);
+#endif
     cmSystemTools::Stdout(msg);
   }
 }
@@ -92,7 +96,9 @@ void cmQtAutoGenerator::Logger::Error(GenT genType,
     cmStrCat('\n', HeadLine(cmStrCat(GeneratorName(genType), " error")),
              message, cmHasSuffix(message, '\n') ? "\n" : "\n\n");
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Mutex_);
+#endif
     cmSystemTools::Stderr(msg);
   }
 }
@@ -108,7 +114,9 @@ void cmQtAutoGenerator::Logger::ErrorCommand(
   msg += cmStrCat(HeadLine("Output"), output,
                   cmHasSuffix(output, '\n') ? "\n" : "\n\n");
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Mutex_);
+#endif
     cmSystemTools::Stderr(msg);
   }
 }
diff --git a/Source/cmQtAutoGenerator.h b/Source/cmQtAutoGenerator.h
index b4f057d..e0970f6 100644
--- a/Source/cmQtAutoGenerator.h
+++ b/Source/cmQtAutoGenerator.h
@@ -55,7 +55,9 @@ public:
     static std::string HeadLine(cm::string_view title);
 
   private:
+#ifndef __serenity__
     mutable std::mutex Mutex_;
+#endif
     unsigned int Verbosity_ = 0;
     bool ColorOutput_ = false;
   };
diff --git a/Source/cmQtAutoMocUic.cxx b/Source/cmQtAutoMocUic.cxx
index 9cb172b..a365c96 100644
--- a/Source/cmQtAutoMocUic.cxx
+++ b/Source/cmQtAutoMocUic.cxx
@@ -586,8 +586,10 @@ private:
   // -- Worker thread pool
   std::atomic<bool> JobError_ = ATOMIC_VAR_INIT(false);
   cmWorkerPool WorkerPool_;
+#ifndef __serenity__
   // -- Concurrent processing
   mutable std::mutex CMakeLibMutex_;
+#endif
 };
 
 cmQtAutoMocUicT::IncludeKeyT::IncludeKeyT(std::string const& key,
@@ -2612,7 +2614,9 @@ void cmQtAutoMocUicT::CreateParseJobs(SourceFileMapT const& sourceMap)
 /** Concurrently callable implementation of cmSystemTools::CollapseFullPath */
 std::string cmQtAutoMocUicT::CollapseFullPathTS(std::string const& path) const
 {
+#ifndef __serenity__
   std::lock_guard<std::mutex> guard(CMakeLibMutex_);
+#endif
   return cmSystemTools::CollapseFullPath(path, ProjectDirs().CurrentSource);
 }
 
diff --git a/Source/cmUVHandlePtr.cxx b/Source/cmUVHandlePtr.cxx
index df2f64e..154b816 100644
--- a/Source/cmUVHandlePtr.cxx
+++ b/Source/cmUVHandlePtr.cxx
@@ -137,16 +137,22 @@ struct uv_handle_deleter<uv_async_t>
    * which is mandated by the standard for Deleter on
    * shared_ptrs.
    */
+#ifndef __serenity__
   std::shared_ptr<std::mutex> handleMutex;
+#endif
 
   uv_handle_deleter()
+#ifndef __serenity__
     : handleMutex(std::make_shared<std::mutex>())
+#endif
   {
   }
 
   void operator()(uv_async_t* handle)
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(*handleMutex);
+#endif
     handle_default_delete(handle);
   }
 };
@@ -156,7 +162,9 @@ void uv_async_ptr::send()
   auto deleter = std::get_deleter<uv_handle_deleter<uv_async_t>>(this->handle);
   assert(deleter);
 
+#ifndef __serenity__
   std::lock_guard<std::mutex> lock(*deleter->handleMutex);
+#endif
   if (this->handle) {
     uv_async_send(*this);
   }
diff --git a/Source/cmWorkerPool.cxx b/Source/cmWorkerPool.cxx
index 12aba4f..a3f3897 100644
--- a/Source/cmWorkerPool.cxx
+++ b/Source/cmWorkerPool.cxx
@@ -382,10 +382,12 @@ public:
   cmWorkerPoolWorker(cmWorkerPoolWorker const&) = delete;
   cmWorkerPoolWorker& operator=(cmWorkerPoolWorker const&) = delete;
 
+#ifndef __serenity__
   /**
    * Set the internal thread
    */
   void SetThread(std::thread&& aThread) { Thread_ = std::move(aThread); }
+#endif
 
   /**
    * Run an external process
@@ -403,13 +405,19 @@ private:
   // -- Process management
   struct
   {
+#ifndef __serenity__
     std::mutex Mutex;
+#endif
     cm::uv_async_ptr Request;
+#ifndef __serenity__
     std::condition_variable Condition;
+#endif
     std::unique_ptr<cmUVReadOnlyProcess> ROP;
   } Proc_;
   // -- System thread
+#ifndef __serenity__
   std::thread Thread_;
+#endif
 };
 
 cmWorkerPoolWorker::cmWorkerPoolWorker(uv_loop_t& uvLoop)
@@ -419,9 +427,11 @@ cmWorkerPoolWorker::cmWorkerPoolWorker(uv_loop_t& uvLoop)
 
 cmWorkerPoolWorker::~cmWorkerPoolWorker()
 {
+#ifndef __serenity__
   if (Thread_.joinable()) {
     Thread_.join();
   }
+#endif
 }
 
 bool cmWorkerPoolWorker::RunProcess(cmWorkerPool::ProcessResultT& result,
@@ -433,7 +443,9 @@ bool cmWorkerPoolWorker::RunProcess(cmWorkerPool::ProcessResultT& result,
   }
   // Create process instance
   {
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Proc_.Mutex);
+#endif
     Proc_.ROP = cm::make_unique<cmUVReadOnlyProcess>();
     Proc_.ROP->setup(&result, true, command, workingDirectory);
   }
@@ -441,10 +453,12 @@ bool cmWorkerPoolWorker::RunProcess(cmWorkerPool::ProcessResultT& result,
   Proc_.Request.send();
   // Wait until the process has been finished and destroyed
   {
+#ifndef __serenity__
     std::unique_lock<std::mutex> ulock(Proc_.Mutex);
     while (Proc_.ROP) {
       Proc_.Condition.wait(ulock);
     }
+#endif
   }
   return !result.error();
 }
@@ -455,7 +469,9 @@ void cmWorkerPoolWorker::UVProcessStart(uv_async_t* handle)
   bool startFailed = false;
   {
     auto& Proc = wrk->Proc_;
+#ifndef __serenity__
     std::lock_guard<std::mutex> lock(Proc.Mutex);
+#endif
     if (Proc.ROP && !Proc.ROP->IsStarted()) {
       startFailed =
         !Proc.ROP->start(handle->loop, [wrk] { wrk->UVProcessFinished(); });
@@ -469,12 +485,14 @@ void cmWorkerPoolWorker::UVProcessStart(uv_async_t* handle)
 
 void cmWorkerPoolWorker::UVProcessFinished()
 {
+#ifndef __serenity__
   std::lock_guard<std::mutex> lock(Proc_.Mutex);
   if (Proc_.ROP && (Proc_.ROP->IsFinished() || !Proc_.ROP->IsStarted())) {
     Proc_.ROP.reset();
   }
   // Notify idling thread
   Proc_.Condition.notify_one();
+#endif
 }
 
 /**
@@ -521,7 +539,9 @@ public:
   cm::uv_async_ptr UVRequestEnd;
 
   // -- Thread pool and job queue
+#ifndef __serenity__
   std::mutex Mutex;
+#endif
   bool Processing = false;
   bool Aborting = false;
   bool FenceProcessing = false;
@@ -529,8 +549,10 @@ public:
   unsigned int WorkersIdle = 0;
   unsigned int JobsProcessing = 0;
   std::deque<cmWorkerPool::JobHandleT> Queue;
+#ifndef __serenity__
   std::condition_variable Condition;
   std::condition_variable ConditionFence;
+#endif
   std::vector<std::unique_ptr<cmWorkerPoolWorker>> Workers;
 
   // -- References
@@ -593,18 +615,24 @@ bool cmWorkerPoolInternal::Process()
 void cmWorkerPoolInternal::Abort()
 {
   // Clear all jobs and set abort flag
+#ifndef __serenity__
   std::lock_guard<std::mutex> guard(Mutex);
+#endif
   if (!Aborting) {
     // Register abort and clear queue
     Aborting = true;
     Queue.clear();
+#ifndef __serenity__
     Condition.notify_all();
+#endif
   }
 }
 
 inline bool cmWorkerPoolInternal::PushJob(cmWorkerPool::JobHandleT&& jobHandle)
 {
+#ifndef __serenity__
   std::lock_guard<std::mutex> guard(Mutex);
+#endif
   if (Aborting) {
     return false;
   }
@@ -612,7 +640,9 @@ inline bool cmWorkerPoolInternal::PushJob(cmWorkerPool::JobHandleT&& jobHandle)
   Queue.emplace_back(std::move(jobHandle));
   // Notify an idle worker if there's one
   if (WorkersIdle != 0) {
+#ifndef __serenity__
     Condition.notify_one();
+#endif
   }
   // Return success
   return true;
@@ -630,11 +660,17 @@ void cmWorkerPoolInternal::UVSlotBegin(uv_async_t* handle)
       gint.Workers.emplace_back(
         cm::make_unique<cmWorkerPoolWorker>(*gint.UVLoop));
     }
+#ifndef __serenity__
     // Start worker threads
     for (unsigned int ii = 0; ii != num; ++ii) {
       gint.Workers[ii]->SetThread(
         std::thread(&cmWorkerPoolInternal::Work, &gint, ii));
     }
+#else
+    for (unsigned int ii = 0; ii != num; ++ii) {
+        gint.Work(ii);
+    }
+#endif
   }
   // Destroy begin request
   gint.UVRequestBegin.reset();
@@ -652,7 +688,9 @@ void cmWorkerPoolInternal::UVSlotEnd(uv_async_t* handle)
 void cmWorkerPoolInternal::Work(unsigned int workerIndex)
 {
   cmWorkerPool::JobHandleT jobHandle;
+#ifndef __serenity__
   std::unique_lock<std::mutex> uLock(Mutex);
+#endif
   // Increment running workers count
   ++WorkersRunning;
   // Enter worker main loop
@@ -664,7 +702,9 @@ void cmWorkerPoolInternal::Work(unsigned int workerIndex)
     // Wait for new jobs on the main CV
     if (Queue.empty()) {
       ++WorkersIdle;
+#ifndef __serenity__
       Condition.wait(uLock);
+#endif
       --WorkersIdle;
       continue;
     }
@@ -672,7 +712,9 @@ void cmWorkerPoolInternal::Work(unsigned int workerIndex)
     // If there is a fence currently active or waiting,
     // sleep on the main CV and try again.
     if (FenceProcessing) {
+#ifndef __serenity__
       Condition.wait(uLock);
+#endif
       continue;
     }
 
@@ -687,12 +729,16 @@ void cmWorkerPoolInternal::Work(unsigned int workerIndex)
       raisedFence = true;
       // Wait on the Fence CV until all pending jobs are done.
       while (JobsProcessing != 0 && !Aborting) {
+#ifndef __serenity__
         ConditionFence.wait(uLock);
+#endif
       }
       // When aborting, explicitly kick all threads alive once more.
       if (Aborting) {
         FenceProcessing = false;
+#ifndef __serenity__
         Condition.notify_all();
+#endif
         break;
       }
     }
@@ -700,10 +746,14 @@ void cmWorkerPoolInternal::Work(unsigned int workerIndex)
     // Unlocked scope for job processing
     ++JobsProcessing;
     {
+#ifndef __serenity__
       uLock.unlock();
+#endif
       jobHandle->Work(Pool, workerIndex); // Process job
       jobHandle.reset();                  // Destroy job
+#ifndef __serenity__
       uLock.lock();
+#endif
     }
     --JobsProcessing;
 
@@ -712,12 +762,16 @@ void cmWorkerPoolInternal::Work(unsigned int workerIndex)
     // is done.
     if (raisedFence) {
       FenceProcessing = false;
+#ifndef __serenity__
       Condition.notify_all();
+#endif
     }
     // If fence processing is still not done, notify the
     // the fencing worker when all active jobs are done.
     if (FenceProcessing && JobsProcessing == 0) {
+#ifndef __serenity__
       ConditionFence.notify_all();
+#endif
     }
   }
 
